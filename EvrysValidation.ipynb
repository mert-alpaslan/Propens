{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def CheckColumnNames(expected_column_labels,dataframe,sheetname):\n",
    "    \"\"\"\n",
    "    First Arg: expected labels of columns as a list\n",
    "    Second Arg: dataframe of the sheet\n",
    "    Third Arg: The name of the sheet\n",
    "    \"\"\"\n",
    "    for label in expected_column_labels:\n",
    "        if label not in dataframe.columns:\n",
    "            raise KeyError(\"Column '{}' could not be found in the {} sheet. Please check the column name!\".format(label,sheetname))    \n",
    "\n",
    "def ValidateSiteSheet(dataframe):\n",
    "    expected_column_labels=['Name', 'area', 'slacknode', 'lat', 'long', 'ctrarea', 'primpos',\n",
    "       'primneg', 'secpos', 'secneg', 'terpos', 'terneg', 'syncharea',\n",
    "       'htworegion']\n",
    "    CheckColumnNames(expected_column_labels,dataframe,\"Site\")\n",
    "\n",
    "    exclusive_urbs_columns = [\"area\"]\n",
    "    dataframe = dataframe.drop(exclusive_urbs_columns, axis=\"columns\")\n",
    "\n",
    "    dataframe = dataframe.rename(columns={\"Name\":\"Site\"})\n",
    "    dataframe = dataframe.set_index([\"Site\"])\n",
    "\n",
    "    columns_ordered = ['slacknode', 'lat', 'long', 'ctrarea', 'primpos', 'primneg',\n",
    "       'secpos', 'secneg', 'terpos', 'terneg', 'syncharea', 'htworegion']\n",
    "    dataframe = dataframe.reindex(columns=columns_ordered)\n",
    "    return dataframe\n",
    "\n",
    "#Modifies the commodity sheet and relabels the data for further use.\n",
    "def ValidateCommoditySheet(dataframe):\n",
    "    expected_column_labels = ['Site', 'Commodity', 'Type', 'price', 'max', 'maxperhour', 'annual',\n",
    "       'losses']\n",
    "    CheckColumnNames(expected_column_labels,dataframe,'Commodity')\n",
    "\n",
    "    exclusive_urbs_columns_commodity = [\"max\", \"maxperhour\"]\n",
    "    dataframe = dataframe.drop(exclusive_urbs_columns_commodity, axis='columns')\n",
    "\n",
    "    dataframe = dataframe.rename(columns={'Commodity':'Co',\"Type\":\"type\"})\n",
    "    dataframe = dataframe.set_index([\"Site\",\"Co\"])\n",
    "    columns_ordered=[\"price\",\"annual\",\"losses\",\"type\"]\n",
    "    dataframe = dataframe.reindex(columns=columns_ordered)\n",
    "    return dataframe  \n",
    "\n",
    "#Modifies the process sheet and relabels the data for further use. \n",
    "#Incomplete\n",
    "def ValidateProcessSheet(dataframe):\n",
    "    #Check the column labels\n",
    "    expected_column_labels = ['Site', 'Process', 'inst-cap', 'cap-lo', 'cap-up', 'max-grad',\n",
    "       'min-fraction', 'inv-cost', 'fix-cost', 'var-cost', 'wacc', 'y',\n",
    "       'area-per-cap', 'act-up', 'on-off', 'start-cost', 'reserve-cost', 'ru',\n",
    "       'rd', 'rumax', 'rdmax', 'cotwo', 'detail', 'lambda', 'heatmax',\n",
    "       'maxdeltaT', 'heatupcost', 'su', 'sd', 'hotstart', 'pdt', 'pot',\n",
    "       'prepow', 'pretemp', 'preheat', 'prestate', 'precaponline', 'year']\n",
    "    CheckColumnNames(expected_column_labels,dataframe,'Process')\n",
    "    \n",
    "    #Remove urbs exclusive columns\n",
    "    exclusive_urbs_columns_process = [\"cap-lo\",\"cap-up\",\"max-grad\",\"inv-cost\",\"fix-cost\",\"var-cost\",\"wacc\",\"y\",\"area-per-cap\"]\n",
    "    dataframe = dataframe.drop(exclusive_urbs_columns_process, axis='columns')\n",
    "\n",
    "    #relabel columns\n",
    "    dataframe = dataframe.rename(columns={\"Process\":\"Pro\", \"min-fraction\":\"act-lo\", \"inst-cap\": \"Inst-cap\"})\n",
    "\n",
    "    #Set indexes \n",
    "    dataframe = dataframe.set_index([\"Site\",\"Pro\"]) #\"CoIn\",\"CoOut\" is missing\n",
    "    \n",
    "    return dataframe\n",
    "\n",
    "#Modifies the transmission sheet and relabels the data for further use. \n",
    "def ValidateTransmissionSheet(dataframe):\n",
    "    #Check the columns\n",
    "    expected_column_labels = ['Site In', 'Site Out', 'Transmission', 'Commodity', 'eff', 'inv-cost',\n",
    "       'fix-cost', 'var-cost', 'inst-cap', 'cap-lo', 'cap-up', 'wacc',\n",
    "       'depreciation', 'reactance', 'difflimit', 'base_voltage',\n",
    "       'cap-up-therm', 'angle-up', 'u2b', 'dc-flow', 'length', 'react-pu',\n",
    "       'PSTmax', 'idx']\n",
    "    CheckColumnNames(expected_column_labels,dataframe,\"Transmission\")\n",
    "\n",
    "    #Drop unnecessary columns\n",
    "    exclusive_urbs_columns_transmission = [\"inv-cost\",\"fix-cost\",\"wacc\",\"depreciation\",\"difflimit\",\"base_voltage\"]\n",
    "    dataframe = dataframe.drop(exclusive_urbs_columns_transmission, axis=\"columns\")\n",
    "\n",
    "    #Relabel the columns\n",
    "    dataframe = dataframe.rename(columns={\"Site In\":\"SitIn\", \"Site Out\":\"SitOut\", \n",
    "    \"Commodity\":\"Co\", \"cap-lo\":\"act-lo\", \"cap-up\":\"act-up\",\"Transmission\":\"tr_type\"}) \n",
    "\n",
    "    #Set indexes\n",
    "    dataframe = dataframe.set_index([\"SitIn\",\"SitOut\",\"Co\",\"tr_type\"])\n",
    "\n",
    "    #Ordering\n",
    "    columns_ordered = ['SitIn', 'SitOut', 'Co', 'eff', 'var-cost', 'inst-cap', 'act-lo',\n",
    "       'act-up', 'reactance', 'cap-up-therm', 'angle-up', 'u2b', 'dc-flow',\n",
    "       'length', 'react-pu', 'tr_type', 'PSTmax', 'idx']\n",
    "    dataframe = dataframe.reindex(columns=columns_ordered)\n",
    "\n",
    "    return dataframe\n",
    "\n",
    "def ValidateStorageSheet(dataframe):\n",
    "    #Check Columns\n",
    "    expected_column_labels = ['Site', 'Storage', 'Commodity', 'inst-cap-c', 'cap-lo-c', 'cap-up-c',\n",
    "       'inst-cap-p', 'cap-lo-p', 'cap-up-p', 'eff-in', 'eff-out', 'inv-cost-p',\n",
    "       'inv-cost-c', 'fix-cost-p', 'fix-cost-c', 'var-cost-p', 'var-cost-c',\n",
    "       'wacc', 'depreciation', 'init', 'discharge', 'ep-ratio', 'inst-cap-pi',\n",
    "       'inst-cap-po', 'var-cost-pi', 'var-cost-po', 'act-lo-pi', 'act-up-pi',\n",
    "       'act-lo-po', 'act-up-po', 'act-lo-c', 'act-up-c', 'precont', 'prepowin',\n",
    "       'prepowout', 'ru', 'rd', 'rumax', 'rdmax', 'seasonal', 'ctr']\n",
    "    CheckColumnNames(expected_column_labels,dataframe,\"Storage\")\n",
    "\n",
    "    #Drop unneccesary columns\n",
    "    exclusive_urbs_columns = [\"cap-lo-c\",\"cap-up-c\",\"inst-cap-p\",\"cap-lo-p\",\"cap-up-p\",\"inv-cost-p\",\"inv-cost-c\",\"fix-cost-p\",\n",
    "    \"fix-cost-c\",\"var-cost-p\",\"wacc\",\"discharge\",\"ep-ratio\"]\n",
    "    dataframe = dataframe.drop(exclusive_urbs_columns, axis='columns')\n",
    "\n",
    "    #Relabel columns for further use\n",
    "    dataframe = dataframe.rename(columns={\"Storage\":\"Sto\",\"Commodity\":\"Co\"})\n",
    "\n",
    "    #Indexing\n",
    "    dataframe = dataframe.set_index([\"Site\",\"Sto\",\"Co\"])\n",
    "\n",
    "    #Ordering\n",
    "    column_names_order = ['inst-cap-pi', 'inst-cap-po', 'inst-cap-c',\n",
    "       'eff-in', 'eff-out', 'var-cost-pi', 'var-cost-po', 'var-cost-c',\n",
    "       'act-lo-pi', 'act-up-pi', 'act-lo-po', 'act-up-po', 'act-lo-c',\n",
    "       'act-up-c', 'precont', 'prepowin', 'prepowout', 'ru', 'rd', 'rumax',\n",
    "       'rdmax', 'seasonal', 'ctr']\n",
    "    dataframe = dataframe.reindex(columns=column_names_order)\n",
    "\n",
    "    return dataframe\n",
    "\n",
    "def ValidateDsmSheet(dataframe):\n",
    "    expected_column_labels = ['Site', 'Commodity', 'delay', 'eff', 'recov', 'cap-max-do',\n",
    "       'cap-max-up', 'rel-inst-cap', 'var-cost']\n",
    "    CheckColumnNames(expected_column_labels,dataframe,\"DSM\")\n",
    "\n",
    "    #Drop unnecesary columns\n",
    "    exclusive_urbs_columns = [\"cap-max-do\",\"cap-max-up\"]\n",
    "    dataframe = dataframe.drop(exclusive_urbs_columns, axis=\"columns\")\n",
    "\n",
    "    #Relabel columns for further use\n",
    "    dataframe = dataframe.rename(columns={'Commodity':\"Co\",\"recov\":\"recovery\"})\n",
    "    \n",
    "    #Indexing\n",
    "    dataframe = dataframe.set_index([\"Site\",\"Co\"])\n",
    "\n",
    "    #ordering\n",
    "    columns_ordered=['rel-inst-cap', 'eff', 'delay', 'recovery', 'var-cost']\n",
    "    dataframe = dataframe.reindex(columns=columns_ordered)\n",
    "    return dataframe\n",
    "\n",
    "def ValidateSiteNames(dfSite,dfCommodity,dfProcess,dfTransmission,dfStorage,dfDSM):\n",
    "    sites = dfSite.index.tolist()\n",
    "    #Check site names in commodity sheet against site sheet\n",
    "    for site in dfCommodity.index.levels[0].tolist():\n",
    "        if site not in sites:\n",
    "            raise KeyError(\"The site name '{}' in Commodity sheet is not listed in the sheet 'Site'!\".format(site))\n",
    "    #check site names in process sheet against site sheet\n",
    "    for site in dfProcess.index.levels[0].tolist():\n",
    "        if site not in sites:\n",
    "            raise KeyError(\"The site name '{}' in Process sheet is not listed in the sheet 'Site'!\".format(site))\n",
    "    #Check site names in transmission sheet against site sheet\n",
    "    for site in dfTransmission.index.levels[0].tolist():\n",
    "        if site not in sites:\n",
    "            raise KeyError(\"The site name '{}' in Transmission sheet at the column 'Site In' is not listed in the sheet 'Site'\".format(site))\n",
    "    for site in dfTransmission.index.levels[1].tolist():\n",
    "        if site not in sites:\n",
    "            raise KeyError(\"The site name '{}' in Transmission sheet at the column 'Site Out' is not listed in the sheet 'Site'\".format(site))\n",
    "    #Check site names in Storage sheet against site sheet\n",
    "    for site in dfStorage.index.levels[0].tolist():\n",
    "        if site not in sites:\n",
    "            raise KeyError(\"The site name '{}' in Storage sheet is not listed in the sheet 'Site'!\".format(site))\n",
    "    #Check site names in DSM sheet against site sheet\n",
    "    for site in dfDSM.index.levels[0].tolist():\n",
    "        if site not in sites:\n",
    "            raise KeyError(\"The site name '{}' in DSM sheet is not listed in the sheet 'Site'!\".format(site))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          slacknode        lat      long  ctrarea  primpos  primneg  secpos  \\\n",
      "Site                                                                          \n",
      "DEU00001        1.0  47.811798  8.201898      1.0      0.0      0.0     0.0   \n",
      "DEU00002        0.0  49.209994  8.645225      1.0      0.0      0.0     0.0   \n",
      "DEU00003        0.0  48.972296  9.376182      1.0      0.0      0.0     0.0   \n",
      "DEU00004        0.0  48.170679  9.380220      1.0      0.0      0.0     0.0   \n",
      "DEU00005        0.0  48.170679  9.380220      1.0      0.0      0.0     0.0   \n",
      "\n",
      "          secneg  terpos  terneg  syncharea  htworegion  \n",
      "Site                                                     \n",
      "DEU00001     0.0     0.0     0.0        1.0         0.0  \n",
      "DEU00002     0.0     0.0     0.0        1.0         0.0  \n",
      "DEU00003     0.0     0.0     0.0        1.0         0.0  \n",
      "DEU00004     0.0     0.0     0.0        1.0         0.0  \n",
      "DEU00005     0.0     0.0     0.0        1.0         1.0  \n",
      "--^----^----^----^----^----^----^----^----^----^----^----^----^----^----^----^----^----^----^----^----^----^----^----^----^----^----^----^----^----^----^----^----^----^----^----^----^----^----^----^----^----^--\n",
      "       slacknode  lat  long  ctrarea  primpos  primneg  secpos  secneg  \\\n",
      "Site                                                                     \n",
      "Mid          NaN  NaN   NaN      NaN      NaN      NaN     NaN     NaN   \n",
      "South        NaN  NaN   NaN      NaN      NaN      NaN     NaN     NaN   \n",
      "North        NaN  NaN   NaN      NaN      NaN      NaN     NaN     NaN   \n",
      "\n",
      "       terpos  terneg  syncharea  htworegion  \n",
      "Site                                          \n",
      "Mid       NaN     NaN        NaN         NaN  \n",
      "South     NaN     NaN        NaN         NaN  \n",
      "North     NaN     NaN        NaN         NaN  \n"
     ]
    }
   ],
   "source": [
    "#Site\n",
    "excel=\"data\\onesyncharea.xlsx\"\n",
    "xls = pd.ExcelFile(excel)\n",
    "sites = xls.parse('Sites', index_col=[0], convert_float=False)\n",
    "print(sites.head())\n",
    "print(\"--^--\"*42)\n",
    "\n",
    "newExcel=\"data\\propens.xlsx\"\n",
    "xls = pd.ExcelFile(newExcel)\n",
    "sites = xls.parse(\"Site\", convert_float=False)\n",
    "sites = ValidateSiteSheet(sites)\n",
    "print(sites.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  price        annual  losses       type\n",
      "Site     Co                                             \n",
      "DEU00001 Coal  21.92157  0.000000e+00     0.0  SUP-Stock\n",
      "DEU00002 Coal  21.92157  0.000000e+00     0.0  SUP-Stock\n",
      "DEU00003 Coal  21.92157  0.000000e+00     0.0  SUP-Stock\n",
      "DEU00004 Coal  21.92157  0.000000e+00     0.0  SUP-Stock\n",
      "DEU00001 Elec   0.00000  1.505621e+07     0.0        DEM\n",
      "--^----^----^----^----^----^----^----^----^----^----^----^----^----^----^----^----^----^----^----^----^----^----^----^----^----^----^----^----^----^----^----^----^----^----^----^----^----^----^----^----^----^--\n",
      "            price  annual  losses    type\n",
      "Site Co                                  \n",
      "Mid  Solar    NaN     NaN     NaN   SupIm\n",
      "     Wind     NaN     NaN     NaN   SupIm\n",
      "     Hydro    NaN     NaN     NaN   SupIm\n",
      "     Elec     NaN     NaN     NaN  Demand\n",
      "     Coal     7.0     NaN     NaN   Stock\n"
     ]
    }
   ],
   "source": [
    "#Commodity\n",
    "excel=\"data\\onesyncharea.xlsx\"\n",
    "xls = pd.ExcelFile(excel)\n",
    "commodities = xls.parse('Commodities', index_col=[0,1], convert_float=False)\n",
    "print(commodities.head())\n",
    "print('--^--'*42)\n",
    "\n",
    "newExcel=\"data\\propens.xlsx\"\n",
    "xls = pd.ExcelFile(newExcel)\n",
    "commodity = xls.parse('Commodity', convert_float=False)\n",
    "commodity = ValidateCommoditySheet(commodity)\n",
    "print(commodity.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
